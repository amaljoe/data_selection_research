{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-24T19:17:20.855563Z",
     "start_time": "2025-03-24T19:17:20.314829Z"
    }
   },
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "# Path to your fine-tuned model\n",
    "model_path = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "\n",
    "# Load the model\n",
    "llm = LLM(model_path, tensor_parallel_size=1)\n",
    "\n",
    "# Example prompts\n",
    "prompts = [\"Explain the concept of transformers in AI.\", \"Summarize this article.\"]\n",
    "sampling_params = SamplingParams(max_tokens=512)\n",
    "\n",
    "# Generate responses\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "for output in outputs:\n",
    "    print(output)"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers.modeling_rope_utils'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LLM, SamplingParams\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# Path to your fine-tuned model\u001B[39;00m\n\u001B[32m      4\u001B[39m model_path = \u001B[33m\"\u001B[39m\u001B[33mmicrosoft/Phi-3-mini-128k-instruct\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/llm-general2/lib/python3.12/site-packages/vllm/__init__.py:11\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mengine\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01marg_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AsyncEngineArgs, EngineArgs\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mengine\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01masync_llm_engine\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AsyncLLMEngine\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mengine\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mllm_engine\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LLMEngine\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/llm-general2/lib/python3.12/site-packages/vllm/engine/arg_utils.py:15\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01menvs\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01menvs\u001B[39;00m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m version\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfig\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (CacheConfig, CompilationConfig, ConfigFormat,\n\u001B[32m     16\u001B[39m                          DecodingConfig, DeviceConfig, HfOverrides,\n\u001B[32m     17\u001B[39m                          KVTransferConfig, LoadConfig, LoadFormat, LoRAConfig,\n\u001B[32m     18\u001B[39m                          ModelConfig, ModelImpl, ObservabilityConfig,\n\u001B[32m     19\u001B[39m                          ParallelConfig, PoolerConfig, PromptAdapterConfig,\n\u001B[32m     20\u001B[39m                          SchedulerConfig, SpeculativeConfig, TaskOption,\n\u001B[32m     21\u001B[39m                          TokenizerPoolConfig, VllmConfig)\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexecutor\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexecutor_base\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExecutorBase\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlogger\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m init_logger\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/llm-general2/lib/python3.12/site-packages/vllm/config.py:33\u001B[39m\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msampling_params\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m GuidedDecodingParams\n\u001B[32m     32\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtracing\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m is_otel_available, otel_import_error_traceback\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtransformers_utils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfig\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     34\u001B[39m     ConfigFormat, get_config, get_hf_image_processor_config,\n\u001B[32m     35\u001B[39m     get_hf_text_config, get_pooling_config,\n\u001B[32m     36\u001B[39m     get_sentence_transformer_tokenizer_config, is_encoder_decoder,\n\u001B[32m     37\u001B[39m     try_get_generation_config, uses_mrope)\n\u001B[32m     38\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtransformers_utils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01ms3_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m S3Model\n\u001B[32m     39\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtransformers_utils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m is_s3\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/llm-general2/lib/python3.12/site-packages/vllm/transformers_utils/config.py:31\u001B[39m\n\u001B[32m     28\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlogger\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m init_logger\n\u001B[32m     29\u001B[39m \u001B[38;5;66;03m# yapf conflicts with isort for this block\u001B[39;00m\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m# yapf: disable\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtransformers_utils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfigs\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (ChatGLMConfig, Cohere2Config,\n\u001B[32m     32\u001B[39m                                              DbrxConfig, DeepseekVLV2Config,\n\u001B[32m     33\u001B[39m                                              EAGLEConfig, ExaoneConfig,\n\u001B[32m     34\u001B[39m                                              H2OVLChatConfig,\n\u001B[32m     35\u001B[39m                                              InternVLChatConfig, JAISConfig,\n\u001B[32m     36\u001B[39m                                              MedusaConfig, MllamaConfig,\n\u001B[32m     37\u001B[39m                                              MLPSpeculatorConfig, MPTConfig,\n\u001B[32m     38\u001B[39m                                              NemotronConfig, NVLM_D_Config,\n\u001B[32m     39\u001B[39m                                              Olmo2Config, RWConfig,\n\u001B[32m     40\u001B[39m                                              SolarConfig, Telechat2Config,\n\u001B[32m     41\u001B[39m                                              UltravoxConfig)\n\u001B[32m     42\u001B[39m \u001B[38;5;66;03m# yapf: enable\u001B[39;00m\n\u001B[32m     43\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtransformers_utils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m check_gguf_file\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/llm-general2/lib/python3.12/site-packages/vllm/transformers_utils/configs/__init__.py:4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtransformers_utils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfigs\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mchatglm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatGLMConfig\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtransformers_utils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfigs\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcohere2\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Cohere2Config\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtransformers_utils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfigs\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdbrx\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DbrxConfig\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvllm\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtransformers_utils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfigs\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdeepseek_vl2\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DeepseekVLV2Config\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/llm-general2/lib/python3.12/site-packages/vllm/transformers_utils/configs/cohere2.py:8\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001B[39;00m\n\u001B[32m      2\u001B[39m \n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# ruff: noqa\u001B[39;00m\n\u001B[32m      4\u001B[39m \n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m# Adapted from\u001B[39;00m\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# https://github.com/huggingface/transformers/blob/main/src/transformers/models/cohere2/configuration_cohere2.py\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PretrainedConfig\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodeling_rope_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m rope_config_validation\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mCohere2Config\u001B[39;00m(PretrainedConfig):\n\u001B[32m     12\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[33;03m    This is the configuration class to store the configuration of a [`CohereModel`]. It is used to instantiate an Cohere\u001B[39;00m\n\u001B[32m     14\u001B[39m \u001B[33;03m    model according to the specified arguments, defining the model architecture.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    122\u001B[39m \u001B[33;03m    ```\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'transformers.modeling_rope_utils'"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
