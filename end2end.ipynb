{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T08:03:12.538830Z",
     "start_time": "2025-03-28T08:03:12.530953Z"
    }
   },
   "cell_type": "code",
   "source": "device = 'cuda:3'",
   "id": "bcf72061a9f8caf2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-28T08:35:21.533793Z",
     "start_time": "2025-03-28T08:35:20.457823Z"
    }
   },
   "source": [
    "from data_loader import get_mix_instruct\n",
    "\n",
    "prompts, references, ds_name = get_mix_instruct(\"train\", 21000)\n",
    "prompts_val, references_val, ds_name_valid = get_mix_instruct(\"validation\", 5000)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mix-instruct_train_21000 found in cache, loading from cache ‚úÖ\n",
      "Dataset: mix-instruct_validation_5000 found in cache, loading from cache ‚úÖ\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T08:35:29.571631Z",
     "start_time": "2025-03-28T08:35:28.570307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utility_functions.delift_se import get_delift_se_utility\n",
    "\n",
    "utility, utility_name = get_delift_se_utility(prompts, references, ds_name)"
   ],
   "id": "972fcd9248770df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility: mix-instruct_train_21000_delift-se found in cache, loading from cache ‚úÖ\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T08:35:29.913376Z",
     "start_time": "2025-03-28T08:35:29.903467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from subset import create_subset, get_subset\n",
    "\n",
    "subset, subset_name = create_subset(utility, utility_name)"
   ],
   "id": "5b8c7f2b2b19e427",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: mix-instruct_train_21000_delift-se_0.3 found in cache, loading from cache ‚úÖ\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T08:53:21.229318Z",
     "start_time": "2025-03-28T08:52:14.400696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from inference import generate_responses\n",
    "from evaluation import compute_metrics\n",
    "# For LLama 3.2 (initial)\n",
    "# Reported BGE: 0.73, ROUGE: 0.28\n",
    "responses_llama, generation_name_llama = generate_responses(prompts_val, 'meta-llama/Llama-3.2-3B', ds_name_valid, device, batch_size=400)\n",
    "compute_metrics(responses_llama, references_val, generation_name_llama, device=device)"
   ],
   "id": "45da7c6508526827",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: mix-instruct_validation_5000_Llama-3.2-3B_100 found in cache, loading from cache ‚úÖ\n",
      "Evaluate: mix-instruct_validation_5000_Llama-3.2-3B_100_bge not found in cache, computing now üèÉ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing BGE: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:49<00:00,  4.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate: mix-instruct_validation_5000_Llama-3.2-3B_100_bge computed and saved to cache ‚úÖ\n",
      "Evaluate: mix-instruct_validation_5000_Llama-3.2-3B_100_rouge not found in cache, computing now üèÉ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ROUGE: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:14<00:00,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate: mix-instruct_validation_5000_Llama-3.2-3B_100_rouge computed and saved to cache ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bge': 0.70930254, 'rouge': 0.20283267710318825}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Before correction: {'bge': 0.70851624, 'rouge': 0.2012717129499011}",
   "id": "b20afce576bfcf43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T09:02:27.261246Z",
     "start_time": "2025-03-28T08:56:23.117900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For LLama 3.2 (finetuned on 30% data selected with DeLiftSE)\n",
    "# Reported BGE: 0.85, ROUGE: 0.55\n",
    "from finetune import fine_tune_model\n",
    "from data_loader import get_mix_instruct\n",
    "from utility_functions.delift_se import get_delift_se_utility\n",
    "from subset import create_subset, get_subset\n",
    "import importlib\n",
    "import inference\n",
    "importlib.reload(inference)\n",
    "from inference import generate_responses\n",
    "from evaluation import compute_metrics\n",
    "\n",
    "\n",
    "\n",
    "prompts, references, ds_name = get_mix_instruct(\"train\", 21000)\n",
    "utility, utility_name = get_delift_se_utility(prompts, references, ds_name)\n",
    "subset, subset_name = create_subset(utility, utility_name)\n",
    "s_prompts, s_references = get_subset(subset, prompts, references)\n",
    "prompts_val, references_val, ds_name_valid = get_mix_instruct(\"validation\", 5000)\n",
    "model_dir = fine_tune_model('meta-llama/Llama-3.2-3B', prompts, references, prompts_val, references_val, subset_name)\n",
    "\n",
    "responses_llama_ft, generation_name_llama_ft = generate_responses(prompts_val, model_dir, ds_name_valid, device, batch_size=400, max_length=150)\n",
    "compute_metrics(responses_llama_ft, references_val, generation_name_llama_ft, device=device)"
   ],
   "id": "7a5f02730edb32b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mix-instruct_train_21000 found in cache, loading from cache ‚úÖ\n",
      "Utility: mix-instruct_train_21000_delift-se found in cache, loading from cache ‚úÖ\n",
      "Subset: mix-instruct_train_21000_delift-se_0.3 found in cache, loading from cache ‚úÖ\n",
      "Dataset: mix-instruct_validation_5000 found in cache, loading from cache ‚úÖ\n",
      "Finetune: Fine-tuned model found in cache. Skipping Training ‚úÖ\n",
      "Generation: mix-instruct_validation_5000_Llama-3.2-3B_mix-instruct_train_21000_delift-se_0.3_150 not found in cache, generating responses üèÉ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0825b1a9e1024a66a57cea51a21f0abc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:   0%|          | 0/13 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:   8%|‚ñä         | 1/13 [00:22<04:27, 22.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  15%|‚ñà‚ñå        | 2/13 [00:44<04:06, 22.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  23%|‚ñà‚ñà‚ñé       | 3/13 [01:06<03:41, 22.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  31%|‚ñà‚ñà‚ñà       | 4/13 [01:28<03:19, 22.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [01:51<02:58, 22.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [02:13<02:36, 22.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [02:34<02:11, 21.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [02:55<01:48, 21.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [03:17<01:27, 21.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [03:39<01:05, 21.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [04:01<00:43, 21.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [04:23<00:21, 21.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [04:36<00:00, 21.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: mix-instruct_validation_5000_Llama-3.2-3B_mix-instruct_train_21000_delift-se_0.3_150 generated and saved to cache ‚úÖ\n",
      "Evaluate: mix-instruct_validation_5000_Llama-3.2-3B_mix-instruct_train_21000_delift-se_0.3_150_bge not found in cache, computing now üèÉ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing BGE: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:57<00:00,  5.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate: mix-instruct_validation_5000_Llama-3.2-3B_mix-instruct_train_21000_delift-se_0.3_150_bge computed and saved to cache ‚úÖ\n",
      "Evaluate: mix-instruct_validation_5000_Llama-3.2-3B_mix-instruct_train_21000_delift-se_0.3_150_rouge not found in cache, computing now üèÉ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ROUGE: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:19<00:00,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate: mix-instruct_validation_5000_Llama-3.2-3B_mix-instruct_train_21000_delift-se_0.3_150_rouge computed and saved to cache ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bge': 0.7600144, 'rouge': 0.2821869937004374}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
