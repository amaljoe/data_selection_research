{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "device = 'cuda:3'",
   "id": "bcf72061a9f8caf2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-27T22:12:56.027568Z",
     "start_time": "2025-03-27T22:12:54.406393Z"
    }
   },
   "source": [
    "from data_loader import get_mix_instruct\n",
    "\n",
    "prompts, references, ds_name = get_mix_instruct(\"train\", 21000)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mix-instruct_train_21000 found in cache, loading from cache ‚úÖ\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T22:12:57.500539Z",
     "start_time": "2025-03-27T22:12:56.073784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utility_functions.delift_se import get_delift_se_utility\n",
    "\n",
    "utility, utility_name = get_delift_se_utility(prompts, references, ds_name)"
   ],
   "id": "972fcd9248770df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility: mix-instruct_train_21000_delift-se found in cache, loading from cache ‚úÖ\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T22:12:58.099162Z",
     "start_time": "2025-03-27T22:12:58.083961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from subset import create_subset, get_subset\n",
    "\n",
    "subset, subset_name = create_subset(utility, utility_name)"
   ],
   "id": "5b8c7f2b2b19e427",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: mix-instruct_train_21000_delift-se_0.3 found in cache, loading from cache ‚úÖ\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-27T22:14:04.952854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from inference import generate_responses\n",
    "\n",
    "# Phi3: 'microsoft/Phi-3-mini-128k-instruct'\n",
    "# LLama: 'meta-llama/Llama-3.2-3B'\n",
    "responses, generation_name = generate_responses(prompts, 'microsoft/Phi-3-mini-128k-instruct', ds_name, device, batch_size=64)"
   ],
   "id": "eb596f8033c54443",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: mix-instruct_train_21000_Phi-3-mini-128k-instruct not found in cache, generating responses üèÉ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "833c4323f7cd4c2f835977fda259d3ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:   0%|          | 0/329 [00:00<?, ?it/s]The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "Generating responses:   0%|          | 1/329 [01:25<7:45:37, 85.18s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T22:15:56.743485592Z",
     "start_time": "2025-03-27T20:30:00.380783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from evaluation import compute_metrics\n",
    "# For Phi3 (initial)\n",
    "# Reported BGE: 0.80, ROUGE: 0.35\n",
    "compute_metrics(responses, references, generation_name, device=device)"
   ],
   "id": "d2f4ff4cc28bdecd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate: mix-instruct_train_21000_Phi-3-mini-128k-instruct_bge found in cache, loading from cache ‚úÖ\n",
      "Evaluate: mix-instruct_train_21000_Phi-3-mini-128k-instruct_rouge found in cache, loading from cache ‚úÖ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bge': 0.808487, 'rouge': 0.21496158928534306}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T22:15:56.748229558Z",
     "start_time": "2025-03-27T20:33:05.171972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For LLama 3.2 (initial)\n",
    "# Reported BGE: 0.73, ROUGE: 0.28\n",
    "responses_llama, generation_name_llama = generate_responses(prompts, 'meta-llama/Llama-3.2-3B', ds_name, device, batch_size=64)\n",
    "compute_metrics(responses_llama, references, generation_name_llama, device=device)"
   ],
   "id": "45da7c6508526827",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: mix-instruct_train_21000_Llama-3.2-3B found in cache, loading from cache ‚úÖ\n",
      "Evaluate: mix-instruct_train_21000_Llama-3.2-3B_bge found in cache, loading from cache ‚úÖ\n",
      "Evaluate: mix-instruct_train_21000_Llama-3.2-3B_rouge found in cache, loading from cache ‚úÖ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bge': 0.7400304, 'rouge': 0.10360998123357584}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T22:04:53.303523Z",
     "start_time": "2025-03-27T22:01:52.114096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For LLama 3.2 (finetuned)\n",
    "# Reported BGE: 0.73, ROUGE: 0.28\n",
    "from finetune import fine_tune_model\n",
    "from data_loader import get_mix_instruct\n",
    "from utility_functions.delift_se import get_delift_se_utility\n",
    "from subset import create_subset, get_subset\n",
    "from inference import generate_responses\n",
    "from evaluation import compute_metrics\n",
    "\n",
    "\n",
    "\n",
    "prompts, references, ds_name = get_mix_instruct(\"train\", 210)\n",
    "utility, utility_name = get_delift_se_utility(prompts, references, ds_name)\n",
    "subset, subset_name = create_subset(utility, utility_name)\n",
    "s_prompts, s_references = get_subset(subset, prompts, references)\n",
    "prompts_val, references_val, ds_name_valid = get_mix_instruct(\"validation\", 50)\n",
    "model_dir = fine_tune_model('meta-llama/Llama-3.2-3B', prompts, references, prompts_val, references_val, subset_name)\n",
    "\n",
    "responses_llama_ft, generation_name_llama_ft = generate_responses(prompts, model_dir, ds_name, device, batch_size=64)\n",
    "compute_metrics(responses_llama_ft, references, generation_name_llama_ft, device=device)"
   ],
   "id": "7a5f02730edb32b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mix-instruct_train_210 found in cache, loading from cache ‚úÖ\n",
      "Utility: mix-instruct_train_210_delift-se found in cache, loading from cache ‚úÖ\n",
      "Subset: mix-instruct_train_210_delift-se_0.3 found in cache, loading from cache ‚úÖ\n",
      "Dataset: mix-instruct_validation_50 found in cache, loading from cache ‚úÖ\n",
      "Finetune: Fine-tuned model found in cache. Skipping Training ‚úÖ\n",
      "Generation: mix-instruct_train_210_Llama-3.2-3B_mix-instruct_train_210_delift-se_0.3 not found in cache, generating responses üèÉ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63bb18a135bf479cba6291f4216a06e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:51<02:34, 51.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [01:33<01:32, 46.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [02:14<00:43, 43.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating responses: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [02:45<00:00, 41.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: mix-instruct_train_210_Llama-3.2-3B_mix-instruct_train_210_delift-se_0.3 generated and saved to cache ‚úÖ\n",
      "Evaluate: mix-instruct_train_210_Llama-3.2-3B_mix-instruct_train_210_delift-se_0.3_bge found in cache, loading from cache ‚úÖ\n",
      "Evaluate: mix-instruct_train_210_Llama-3.2-3B_mix-instruct_train_210_delift-se_0.3_rouge found in cache, loading from cache ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bge': 0.6989159, 'rouge': 0.1114583432053361}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T22:11:13.451067Z",
     "start_time": "2025-03-27T22:11:05.122947Z"
    }
   },
   "cell_type": "code",
   "source": "compute_metrics([r[:int(len(r) * 0.2)] for r in responses_llama_ft], references, generation_name_llama_ft + \"_temp\", device='cuda:0')",
   "id": "385b5516118034a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate: mix-instruct_train_210_Llama-3.2-3B_mix-instruct_train_210_delift-se_0.3_temp_bge not found in cache, computing now üèÉ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing BGE: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate: mix-instruct_train_210_Llama-3.2-3B_mix-instruct_train_210_delift-se_0.3_temp_bge computed and saved to cache ‚úÖ\n",
      "Evaluate: mix-instruct_train_210_Llama-3.2-3B_mix-instruct_train_210_delift-se_0.3_temp_rouge not found in cache, computing now üèÉ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ROUGE: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate: mix-instruct_train_210_Llama-3.2-3B_mix-instruct_train_210_delift-se_0.3_temp_rouge computed and saved to cache ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bge': 0.7549735, 'rouge': 0.3130293886059544}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
