{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-27T20:37:56.473312Z",
     "start_time": "2025-03-27T20:37:55.496552Z"
    }
   },
   "source": [
    "from data_loader import get_mix_instruct\n",
    "\n",
    "prompts, references, ds_name = get_mix_instruct(\"train\", 21000)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mix-instruct_train_21000 found in cache, loading from cache ‚úÖ\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T20:41:12.904644Z",
     "start_time": "2025-03-27T20:37:58.463603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utility_functions.delift_se import get_delift_se_utility\n",
    "\n",
    "utility, utility_name = get_delift_se_utility(prompts, references, ds_name)"
   ],
   "id": "972fcd9248770df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility: mix-instruct_train_21000_delift-se not found in cache, computing now üèÉ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding data to vectors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1313/1313 [02:56<00:00,  7.45it/s]\n",
      "Computing pairwise similarities: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility: mix-instruct_train_21000_delift-se computed and saved to cache ‚úÖ\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-27T20:46:03.294332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from subset import create_subset, get_subset\n",
    "\n",
    "subset, subset_name = create_subset(utility, utility_name)"
   ],
   "id": "5b8c7f2b2b19e427",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: mix-instruct_train_21000_delift-se_0.3 not found in cache, computing now üèÉ\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "de1a4fb2862e46e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T20:15:35.520553Z",
     "start_time": "2025-03-27T20:15:35.407468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from inference import generate_responses\n",
    "\n",
    "# Phi3: 'microsoft/Phi-3-mini-128k-instruct'\n",
    "# LLama: 'meta-llama/Llama-3.2-3B'\n",
    "responses, generation_name = generate_responses(prompts, 'microsoft/Phi-3-mini-128k-instruct', ds_name, 'cuda:3', batch_size=64)"
   ],
   "id": "eb596f8033c54443",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: mix-instruct_train_21000_Phi-3-mini-128k-instruct found in cache, loading from cache ‚úÖ\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T20:30:00.389039Z",
     "start_time": "2025-03-27T20:30:00.380783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from evaluation import compute_metrics\n",
    "# For Phi3 (initial)\n",
    "# Reported BGE: 0.80, ROUGE: 0.35\n",
    "compute_metrics(responses, references, generation_name, device='cuda:0')"
   ],
   "id": "d2f4ff4cc28bdecd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate: mix-instruct_train_21000_Phi-3-mini-128k-instruct_bge found in cache, loading from cache ‚úÖ\n",
      "Evaluate: mix-instruct_train_21000_Phi-3-mini-128k-instruct_rouge found in cache, loading from cache ‚úÖ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bge': 0.808487, 'rouge': 0.21496158928534306}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T20:33:05.252479Z",
     "start_time": "2025-03-27T20:33:05.171972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For LLama 3.2 (initial)\n",
    "# Reported BGE: 0.73, ROUGE: 0.28\n",
    "responses_llama, generation_name_llama = generate_responses(prompts, 'meta-llama/Llama-3.2-3B', ds_name, 'cuda:3', batch_size=64)\n",
    "compute_metrics(responses_llama, references, generation_name_llama, device='cuda:0')"
   ],
   "id": "45da7c6508526827",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: mix-instruct_train_21000_Llama-3.2-3B found in cache, loading from cache ‚úÖ\n",
      "Evaluate: mix-instruct_train_21000_Llama-3.2-3B_bge found in cache, loading from cache ‚úÖ\n",
      "Evaluate: mix-instruct_train_21000_Llama-3.2-3B_rouge found in cache, loading from cache ‚úÖ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bge': 0.7400304, 'rouge': 0.10360998123357584}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T20:33:32.011625Z",
     "start_time": "2025-03-27T20:33:17.638559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "rouge_metric = evaluate.load('rouge')\n",
    "def calculate_evaluate_metric(predictions, references, score=\"rouge\", return_invidiual=True):\n",
    "    \"\"\"\n",
    "    Calculates the similarity (rouge, bleu, or bertscore) between the predictions and references\n",
    "\n",
    "    Args:\n",
    "        predictions: list of strings for the hypothesis\n",
    "        references: list of strings for the reference\n",
    "        score: one of \"rouge\", \"bleu\", \"bertscore\", \"bge\", \"promedeus\"\n",
    "        return_invidiual: if True, it will return the individual scores for corresponding prediction-reference pairs\n",
    "    Returns:\n",
    "        np array of metrics of size 1x1 if return_individual is True, else 1x|predictions|\n",
    "    \"\"\"\n",
    "    if not return_invidiual:\n",
    "        predictions = [predictions]\n",
    "        references = [references]\n",
    "    else:\n",
    "        predictions = [[p] for p in predictions]\n",
    "        references = [[r] for r in references]\n",
    "\n",
    "\n",
    "    if score == \"rouge\":\n",
    "        sim_metric = rouge_metric\n",
    "        metric_key = \"rouge1\"\n",
    "\n",
    "    metrics = []\n",
    "    for p, r in zip(predictions, references):\n",
    "        if score == \"bertscore\":\n",
    "            metrics.append(np.array(sim_metric.compute(predictions=p, references=r, lang=\"en\")[metric_key]).mean())\n",
    "        else:\n",
    "            metrics.append(sim_metric.compute(predictions=p, references=r)[metric_key])\n",
    "    return np.array(metrics)\n",
    "\n",
    "calculate_evaluate_metric(responses_llama[:1000], references[:1000], return_invidiual=False)"
   ],
   "id": "1cb2b004560c7e09",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10462405])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
